{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO9lTbZto3AObu/V9CkLleF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Fx09LCNZ__yA"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","\n","# Data transformation and loaders\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n","\n","train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n","test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"]},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","batch_size = 128\n","#test_batch_size = 256\n","# Download and load the training set\n","trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n","train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","\n","# Download and load the test set\n","testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n","test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"yydSLYiDAJTS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n","test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n","\n","batch_size = 128\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"AwoGA36BAO16"},"execution_count":null,"outputs":[]}]}